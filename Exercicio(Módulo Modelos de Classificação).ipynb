{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.where(ytrain == 1, 2)\n",
    "ytest = np.where(ytest == 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0,Xtrain.shape[0], size = 24)\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "for i in range(len(random_idx)):\n",
    "    idx_i = random_idx[i]\n",
    "    xval = Xtrain[idx_i, :].reshape(28,28)\n",
    "    yval = ytrain[idx_i]\n",
    "    plt.subplot(4,6,i+1)\n",
    "    plt.imshow(xval, cmap = plt.cm.Greys_r)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"label real: \"+str(yval), fontsize = 14, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0,Xtest.shape[0], size = 24)\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "for i in range(len(random_idx)):\n",
    "    idx_i = random_idx[i]\n",
    "    xval = Xtest[idx_i, :].reshape(28,28)\n",
    "    plt.subplot(4,6,i+1)\n",
    "    plt.imshow(xval, cmap = plt.cm.Greys_r)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"É par ou impar?\", fontsize = 14, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims = np.arange(-10,10,0.01)\n",
    "sigmoid_vals = [sigmoid(x) for x in xlims]\n",
    "\n",
    "plt.figure(figsize=[20, 5])\n",
    "plt.title(\"Função Sigmoide\", fontsize = 16, fontweight = 'bold')\n",
    "plt.plot(xlims, sigmoid_vals, c = 'blue', lw = 2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from skleran.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(Xtrain, ytrain)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Executando: ', np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = logreg.predict(Xtrain)\n",
    "\n",
    "qtd_acertos = (predicoes == ytrain).sum()\n",
    "total_inst = ytrain.size\n",
    "\n",
    "acuracia_sgd = qtd_acertos / total_inst\n",
    "print(\"acurácia - em dados de treino - da regressão logística foi de : \", acuracia_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(20).reshape(10,2).round(2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(train_index, val_index)\n",
    "    print(X[train_index])\n",
    "    print()\n",
    "    print(X[val_index])\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "classif__ = LogisticRegression() \n",
    "lista_acuracia_treino = []\n",
    "lista_acuracia_validacao = []\n",
    "\n",
    "for train_index, val_index in kf.split(Xtrain, ytrain):\n",
    "    \n",
    "    Xtrain_folds = Xtrain[train_index]\n",
    "    ytrain_folds = ytrain[train_index]\n",
    "    Xval_fold = Xtrain[val_index]\n",
    "    yval_fold = ytrain[val_index]\n",
    "    \n",
    "    classif__.fit(Xtrain_folds, ytrain_folds)\n",
    "    \n",
    "    pred_treino = classif__.predict(Xtrain_folds)\n",
    "    pred_validacao = classif__.predict(Xval_fold)\n",
    "    \n",
    "    lista_acuracia_treino.append(accuracy_score(y_pred = pred_treino, y_true = ytrain_folds))\n",
    "    lista_acuracia_validacao.append(accuracy_score(y_pred = pred_validacao, y_true = yval_fold))\n",
    "    \n",
    "    \n",
    "print(\"acurácias em treino: \\n\", lista_acuracia_treino, \" \\n| média: \", np.mean(lista_acuracia_treino))\n",
    "print()\n",
    "print(\"acurácias em validação: \\n\", lista_acuracia_validacao, \" \\n| média: \", np.mean(lista_acuracia_validacao))\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator): \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif__ = Never5Classifier()\n",
    "\n",
    "\n",
    "lista_acuracia_treino = []\n",
    "lista_acuracia_validacao = []\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "for train_index, val_index in kf.split(Xtrain, ytrain):\n",
    "    \n",
    "    Xtrain_folds = Xtrain[train_index]\n",
    "    ytrain_folds = ytrain[train_index]\n",
    "    Xval_fold = Xtrain[val_index]\n",
    "    yval_fold = ytrain[val_index]\n",
    "    \n",
    "    classif__.fit(Xtrain_folds, ytrain_folds)\n",
    "    \n",
    "    pred_treino = classif__.predict(Xtrain_folds)\n",
    "    pred_validacao = classif__.predict(Xval_fold)\n",
    "    \n",
    "    lista_acuracia_treino.append(accuracy_score(y_pred = pred_treino, y_true = ytrain_folds))\n",
    "    lista_acuracia_validacao.append(accuracy_score(y_pred = pred_validacao, y_true = yval_fold))\n",
    "    \n",
    "    \n",
    "print(\"acurácias em treino: \\n\", lista_acuracia_treino, \" \\n| média: \", np.mean(lista_acuracia_treino))\n",
    "print()\n",
    "print(\"acurácias em validação: \\n\", lista_acuracia_validacao, \" \\n| média: \", np.mean(lista_acuracia_validacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(recall_list, precision_list, c = 'blue')\n",
    "plt.xlabel(\"Kfold\", fontsize = 14, fontweight = 'bold')\n",
    "plt.ylabel(\"acurácias em treino\", fontsize = 14, fontweight = 'bold')\n",
    "plt.title(\"acurácias em validação\", fontsize = 20, fontweight = 'bold')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
